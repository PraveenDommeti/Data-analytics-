# Data-analytics-
This repository contains a complete data mining case study performed on a publicly available dataset. The project demonstrates the full pipeline of data analysis, including data preprocessing, model application, evaluation, and validation.
In this project, we:
Selected a dataset from an open-source data repository
Performed complete data cleaning and preprocessing
Applied multiple machine learning models
Evaluated model performance using confusion matrix and accuracy
Used 10-fold cross-validation for reliable results
Trained models with various data split ratios (like 70:30, 80:20)

 Steps Involved
Data Loading: Import dataset using Python or a data mining tool like Weka or Orange.

Preprocessing:
1.Handling missing values
2.Encoding categorical variables
3.Feature scaling and normalization
4.Model Building:
5.Applied models like Decision Tree, KNN, Naive Bayes, and SVM

Evaluation:
1.Generated confusion matrix
2.Calculated accuracy, precision, recall, and F1-score

Cross-Validation:
1.Used 10-fold cross-validation to check model generalizability
2.Training on Various Splits:
3.Compared results on different train-test splits (70:30, 80:20, etc.)

Tools & Technologies Used:
Python (Pandas, NumPy, Scikit-learn, Seaborn, Matplotlib)

 Result Summary:
All models were evaluated and compared. Confusion matrix and accuracy scores helped determine the best-performing model for this dataset.
Weka / Orange (GUI-based data mining tools)
